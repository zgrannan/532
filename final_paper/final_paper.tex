\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
% \usepackage{neurips_2021}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
% \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
\usepackage[nonatbib,preprint]{neurips_2021}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage[numbers]{natbib}

\title{Final Paper: A Framework for Leveraging Small Language Models for Synthetic Data Generation for
Fine-Tuning}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Zachary Grannan \\
  \And{}
  Owen Ren
}

\begin{document}

\maketitle

\begin{abstract}
Synthetic data is now commonly used in LLM post-training. However, there has
been less research into the use of domain-specific synthetic data for
fine-tuning purpose-built LLMs. We propose the development of an open-source
agentic framework, in the style of AgentInstruct
\citep{mitra_agentinstruct_2024}, to automatically generate synthetic data for
domain-specific LLM fine-tuning. We will come the performance of LLMs fine-tuned
via our framework to traditional RAG-based approaches.
\end{abstract}

\input{introduction}
\input{related}
\input{methodology}
\input{results_analysis}
\input{discussion}
\input{conclusions}

\clearpage

\bibliographystyle{abbrvnat}
\bibliography{bib}

\end{document}
