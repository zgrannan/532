\section{The Agentic Framework}\label{sec:framework}

In this section, we provide a conceptual overview of the framework we develop,
and describe its implementation in Python.

\subsection{Conceptual Model}

The goal of our framework is to enable the development of the \emph{agentic
flows} as described in the AgentInstruct \citep{mitra_agentinstruct_2024} paper.
At a high level, an agentic flow describes the transformation of initial seed
data into fine-tune examples by computations of coordinating agents.

We initially considered basing our conceptual model on prior work on agentic
frameworks, such as AutoGen \cite{wu2023autogenenablingnextgenllm} and
LangChain's LangGraph \cite{langchain}. In such frameworks, agents are
event-based actors that, when they receive a message, perform some computations
and potentially communicate with other actors.

However, we found that for the purpose of developing agentic flows, this
conceptual model is overly general. In particular, the general agent model
treats the messages sent between agents as being first-class, the notion of data
being transformed is not captured by the model.

Therefore, we develop a new conceptual model that treats the stream of data
being transformed as first-class. Agents are (potentially nondeterministic)
\emph{functions} that manipulate the stream of data, and coordination between
agents occurs via an explicit graph topology. This model is inherently more
restrictive than the general conceptual model, however, there restrictions
enable greater composability. In particular agents for common stream operations
(e.g. \texttt{map} or \texttt{filter}) can easily be composed to form complex
pipelines. In our Python implementation, we provide implementations of such
general-purpose agents.

\subsubsection{Core Concepts}

Our resulting framework is based around three key concepts: \emph{streams},
\emph{agents}, and \emph{pipelines}. A \emph{stream} $\stream{\mathcal{T}}$ is a
potentially infinite list of values of some type $\mathcal{T}$; for example, the
list of numbers in the range $[0, 10]$ is a stream $\stream{\mathbb{N}}$.

An \emph{agent} $\agent : \streamty{\mathcal{T}} \rightarrow
\streamty{\mathcal{U}}$ is a nondeterministic function that maps an \emph{input
stream} $\stream{\mathcal{T}}$ to an output stream $\stream{\mathcal{U}}$.

A \emph{pipeline} is a connected directed graph of agents, containing a unique
\emph{source agent} $\agent{}_{\mathit{source}} : \streamty{\mathcal{T}}
\rightarrow \streamty{\mathcal{U}}$ and a unique \emph{sink agent}
$\agent_{\mathit{sink}} : \streamty{\mathcal{T}'} \rightarrow
\streamty{\mathcal{U}'}$. We note that the source and sink agent are not
necessarily distinct: the simplest pipeline is one consisting of a single agent.
A pipeline defines a nondeterminstic function $\streamty{\mathcal{T}}
\rightarrow \streamty{\mathcal{U}'}$.

\subsection{Python Implementation}

We implement our framework in Python. In our library, we use asynchronous
generators to model streams; in particular a stream containing elememnts of type
\texttt{T} is represented by a value of type \texttt{AsyncIterator[T]}. This was
a natural choice for our use case because generators can easily be created from
data structures (esp. lists) and also directly defined as generator
functions\footnote{For more details see
\url{https://peps.python.org/pep-0525/}}.

 The abstract class
\texttt{Pipeline[T, U]} implements pipelines, and declares the abstract method
\texttt{process : AsyncIterator[T] -> AsyncIterator[U]}. Agents are realized in
our implementation by the abstract class \texttt{Agent[T, U]} (which extends the
\texttt{Pipeline[T, U]} class).

Our library includes built-in classes to facilitate the construction of agents
and pipelines in the framework. Here we present some highlights:

\subsubsection{Caching}

Our library facilitates caching at the per-agent level. This is useful so that
incremental results can be saved, in case a pipeline needs to be restarted or
changed. Additionally, this can save time when the same agent is used in
different pipelines, or even at different stages within the same pipeline.

Caching is enabled via our library's included \texttt{CachingAgent} class.
Intuitively, the caching agent maintains a disk-based map of cached inputs to
cached outputs, and uses the cached result for an input if available, and
otherwise calling the underlying agent to return the result. One requirement on
the underlying agent is that it must be \emph{stateless}: its behaviour upon
receiving a new input should not depend on previously received inputs.

\subsubsection{Concurrency}

By default, agents in a pipeline operate concurrently. For example, in a
pipeline where the output of an agent $a$ is used as input to agent $b$, while
agent $b$ is processing $a$'s output stream, the agent $a$ itself continue to
process elements from its input stream.

However, in data processing pipelines, unrestricted concurrency can cause
performance problems. In particular, to continue the above example, if agent $a$
emits output elements faster than agent $b$ can process them, memory exhaustion
can occur there is insufficient memory to store the as-yet unprocessed outputs
of $a$. To address this issue, our framework supports \emph{backpressure} by
introducing bounded queues between agent connections. When the queue between
e.g. agents $a$ and $b$ is full, agent $a$ is suspended until the queue has
additional space available. Backpressure parameters such as queue size can be
controlled by the user, and even disabled entirely.

We note that in contrast to our framework, features such as backpressure are
challenging to implement in actor-based frameworks, and require careful
modification to actor code. Furthermore, both the caching and concurrency
features of the framework are built using the framework's public API. Therefore,
users of the framework could instead implement their own custom logic for such
functionality.
