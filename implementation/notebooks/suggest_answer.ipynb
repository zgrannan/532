{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "import sys \n",
    "from pprint import pprint\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from IPython import get_ipython\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append((Path(os.getcwd())/ '../').resolve().as_posix())\n",
    "from pipeline.utils.pdf import read_pdf\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from pipeline.helpers import get_json_response, get_messages_response, split_text, list_of_dicts_to_dict_of_lists, upload_to_hf, once, get_async_client, get_json_response_async, get_messages_response_async\n",
    "from datasets import Dataset\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuggesterModel(BaseModel):\n",
    "    suggestions: List[str]\n",
    "    finished: bool\n",
    "\n",
    "class EditorModel(BaseModel):\n",
    "    question: str\n",
    "    answer : str \n",
    "\n",
    "class RefinedQuestionsModel(BaseModel):\n",
    "    questions: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_async_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUGGESTER_PROMPT = \"\"\" \n",
    "    You are provided a pair of question and answer documents.\n",
    "    Your job is to provide suggestions to refine both the question and answer to increase understanding of the context.\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "    Answer: \n",
    "    {answer}\n",
    "    \n",
    "    Return your suggestions as a list of strings in JSON. \n",
    "    If you have no suggestions, return an empty list and set finished to True.\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Summarize the AgentInstruct methodology for creating synthetic datasets for supervised fine-tuning and instruction-tuning.\"\n",
    "answer = \"\"\"The AgentInstruct methodology is a structured approach to create synthetic datasets for supervised fine-tuning and instruction-tuning of Large Language Models (LLMs). The methodology consists of three main flows: Content Transformation Flow, Seed Instruction Generation Flow, and Instruction Refinement Flow.\n",
    "\n",
    "**Content Transformation Flow**\n",
    "\n",
    "1. Assemble a collection of raw seeds (e.g., textbook chapters, web articles, code snippets).\n",
    "2. Transform the seed with the aid of one or more content transformation agents to create an intermediate representation that simplifies the creation of instructions tailored to specific objectives.\n",
    "3. This flow is instrumental in generating high-quality data and introducing diversity.\n",
    "\n",
    "**Seed Instruction Generation Flow**\n",
    "\n",
    "1. Take as input the transformed seed from the Content Transformation Flow.\n",
    "2. Generate a set of diverse instructions using multiple agents, each targeting different question types (e.g., literal comprehension, critical comprehension, evaluative comprehension).\n",
    "3. This flow introduces diversity by relying on a pre-defined taxonomy.\n",
    "\n",
    "**Instruction Refinement Flow**\n",
    "\n",
    "1. Take as input the instructions from the Seed Instruction Generation Flow.\n",
    "2. Iteratively enhance their complexity and quality using Suggester-Editor Agents.\n",
    "3. The refinement flow contains multiple suggester-editor agents that modify the passage, question, or answer choices to make them complex or unanswerable.\n",
    "\n",
    "The AgentInstruct methodology is designed to automate the generation process, leveraging raw articles as seeds to foster diversity and ensure that problems generated in different iterations are distinct and of broad coverage. This enables the creation of data at scale with high diversity and varying complexity.\n",
    "\n",
    "**Key Benefits**\n",
    "\n",
    "1. **Automation**: The agentic flows can run autonomously, reducing or eliminating human intervention.\n",
    "2. **Diversity**: AgentInstruct generates both prompts and responses using a large number of agents and a taxonomy of over 100 subcategories.\n",
    "3. **Large quantities of data**: AgentInstruct can create vast amounts of diverse data.\n",
    "\n",
    "**Implementation**\n",
    "\n",
    "The AgentInstruct methodology has been implemented for 17 different skills, each having multiple subcategories. The skills include reading comprehension, question answering, coding, retrieval augmented generation, creative writing, tool use, and more.\n",
    "\n",
    "Source: \"AgentInstruct: Toward Generative Teaching with Agentic Flows\" by Arindam Mitra et al., Microsoft Research.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_3B= \"llama-3.2-3b-instruct\"\n",
    "resp = await get_json_response_async(\n",
    "    client=client,\n",
    "    model=MODEL_3B,\n",
    "    messages=[\n",
    "                    {\"role\": \"system\", \"content\": SUGGESTER_PROMPT.format(question=question, answer=answer)},\n",
    "                ],\n",
    "    response_format=SuggesterModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDITOR_PROMPT = \"\"\" \n",
    "    You are provided a list of suggestions a pair of question and answer documents.\n",
    "    Your job is to apply the suggestions to the question and answer and generate a new answer and question\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "    Answer: \n",
    "    {answer}\n",
    "    \n",
    "    Suggestions:\n",
    "    {suggestions}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp2 = await get_messages_response_async(\n",
    "    client=client,\n",
    "    model=MODEL_3B,\n",
    "    messages=[\n",
    "                    {\"role\": \"system\", \"content\": EDITOR_PROMPT.format(question=question, answer=answer, suggestions=\"\\n\".join(resp.suggestions[0:5]))},\n",
    "                ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = await get_json_response_async(\n",
    "    client=client,\n",
    "    model=MODEL_3B,\n",
    "    messages=[\n",
    "                    {\"role\": \"system\", \"content\": EDITOR_PROMPT.format(question=question, answer=answer, suggestions=\"\\n\".join(resp.suggestions[0:5]))},\n",
    "                ],\n",
    "    response_format=EditorModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.model_dump()['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp.model_dump()['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFINED_QUESTIONS_PROMPT = \"\"\"\n",
    "    You are provided with a question and an answer.\n",
    "    Your job is to generate a set of new questions that can be answered with the given answer but is diverse and approaches \n",
    "    the original question from different perspectives.\n",
    "\n",
    "    Ensure that the generated questions are clear, purposeful, specific, and invoke critical thinking\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    {answer}\n",
    "\n",
    "    Return a list of new questions in JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = await get_json_response_async(\n",
    "    client=client,\n",
    "    model=MODEL_3B,\n",
    "    messages=[\n",
    "                    {\"role\": \"system\", \"content\": REFINED_QUESTIONS_PROMPT.format(question=question, answer=answer)},\n",
    "                ],\n",
    "    response_format=RefinedQuestionsModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List of 17 capabilities for which we implemented AgentInstruct Flows\n",
    "    * Finetuned model could not answer completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leverage RAG to also get similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-nomic-embed-text-v1.5@f32\" # on LM Studio\n",
    "embeddings_func = OpenAIEmbeddings(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"terst\",\n",
    "    check_embedding_ctx_length=False # https://github.com/langchain-ai/langchain/issues/21318\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"test\",\n",
    "    embedding_function=embeddings_func,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFINED_RAG_ANSWER_PROMPT = \"\"\"\n",
    "    You are tasked with answering questions based on a provided text.\n",
    "    You are provided with a question and an initial answer.\n",
    "    You are also provided with some supporting documentation to help create a new response\n",
    "\n",
    "    Your goal is to generate high-quality, detailed answers by following these instructions:\n",
    "    \n",
    "    # Instructions:\n",
    "    1. Reference the Text: Answer directly using relevant details from the text. Avoid introducing unsupported claims.\n",
    "    2. Comprehensive Response: Address all parts of the question thoroughly, covering multiple aspects if needed.\n",
    "    3. Detail-Oriented: Highlight key elements like techniques, processes, models, or challenges, expanding on them for clarity.\n",
    "    4. Organized Structure: Use clear paragraphs or points for complex answers.\n",
    "    5. Clarity and Examples: Ensure the answer is precise and easy to follow. Include examples or quotes from the text when applicable.\n",
    "    6. Include Sources: Clearly reference the source information at the end of the answer.\n",
    "\n",
    "    If the answer is not found in the text, respond with \"NO ANSWER FOUND\"\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Initial Answer:\n",
    "    {answer}\n",
    "\n",
    "    Supporting Documentation:\n",
    "    {docs}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AnswerModel(BaseModel):\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_docs(\n",
    "        vector_store: Chroma,\n",
    "        question: str,\n",
    "        k: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Get RAG response.\"\"\"\n",
    "    docs = vector_store.similarity_search_with_score(question, k=k)\n",
    "    return \"\\n\".join([r[0].page_content for r in docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_docs = get_rag_docs(vector_store, resp.questions[7], k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_resp = await get_messages_response_async(\n",
    "    client=client,\n",
    "    model=MODEL_3B,\n",
    "    messages=[\n",
    "                    {\"role\": \"system\", \"content\": REFINED_RAG_ANSWER_PROMPT.format(question=resp.questions[7], answer=answer, docs=rag_docs)},\n",
    "                ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_resp2 = await get_json_response_async(\n",
    "    client=client,\n",
    "    model=MODEL_3B,\n",
    "    messages=[\n",
    "                    {\"role\": \"system\", \"content\": REFINED_RAG_ANSWER_PROMPT.format(question=resp.questions[7], answer=answer, docs=rag_docs)},\n",
    "                ],\n",
    "    response_format=AnswerModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answer_resp2.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_resp2.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data2/agentinstruct.pdf\", \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    # Attempt to extract title from metadata\n",
    "    if \"/Title\" in reader.metadata:\n",
    "        title= reader.metadata[\"/Title\"]\n",
    "    raise ValueError(\"No title found in metadata\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
