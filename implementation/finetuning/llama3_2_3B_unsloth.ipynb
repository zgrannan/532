{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jfVz96Auw6a"
      },
      "source": [
        "## Using Unsloth to finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Prerequisite Packages"
      ],
      "metadata": {
        "id": "BXimWVZ7-iRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is necessary for colab\n",
        "!pip install python-dotenv\n",
        "!pip install datasets\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM4qXDrpvdl8",
        "outputId": "3a1fa559-bffd-456f-9c26-ad6e0b2e338f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-80vjd64x/unsloth_6dc3d59283704b839fa06da873d3a1a8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-80vjd64x/unsloth_6dc3d59283704b839fa06da873d3a1a8\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 9ca13b836f647e67d6e9ca8bb712403ffaadd607\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth-zoo in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.14)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.7)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.3)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0+cu121)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.34.2)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.6)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.28.post2)\n",
            "Requirement already satisfied: trl<0.9.0 in /usr/local/lib/python3.10/dist-packages (0.8.6)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load `.env`"
      ],
      "metadata": {
        "id": "WrRIVF20-nmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEjj4o6luw6a",
        "outputId": "95c8c5ab-8145-4274-ff7f-71a677f2caf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important Global Parameters"
      ],
      "metadata": {
        "id": "_i-raT4C-xbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FINETUNING_DATASET_NAME=\"test_dataset_2024OCT24\"\n",
        "OUTPUT_MODEL_NAME=\"finetuned_model_2024OCT24\"\n",
        "BASE_MODEL_NAME=\"unsloth/Llama-3.2-3B-Instruct\""
      ],
      "metadata": {
        "id": "-7S3GvWl-6a1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Keys"
      ],
      "metadata": {
        "id": "ZG5PA94w_Js6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Could also insert the token here directly\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_API_KEY\")"
      ],
      "metadata": {
        "id": "i6Fy6R3u6WMD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9GIrquruw6c"
      },
      "source": [
        "Leveraging Unsloth notebooks for finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X-AVcbVxuw6c"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 16000 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "2fe1bc3e9adc4d23a68b70c58fe6247b",
            "5f045515f2e948afbed1eaa42a863e64",
            "b5737cac09f04c82ba77a6743996bb22",
            "2e55562e92f44f998b2db708331bc578",
            "5eba2ef7021a41dfb01521f24b549442",
            "7e329f138556458688fdb827ad56e89d",
            "3661952fe0a9423288c424ab545a18b9",
            "979bd94798e84360bdea1047b6f82714",
            "bcf163bcddcf4722bb55efb9631e031c",
            "066097e8a41747dbb200f56c191911e3",
            "d12d8859fe08497c8960c4615d738286",
            "d23b122aaa474270842c0840ab7c4777",
            "52c2e1ed3a1a4f2e9bbb549fcf3e84d4",
            "cc71bea3bd014085bc0d18db7cb87c90",
            "a73bfefd43de419da5fac7c6c12e63e4",
            "cc266b672f2040c097abea42b60a1180",
            "39729ca458e145e6a019637489652c54",
            "819c5a0a37a249cd9e1905767eecb2ef",
            "5b37909e1bc44e3babbd132cecadcbf7",
            "661f3a1eac7b4bc3ae44e3a250aa7871",
            "d429d427352e446b8b2085cd313ac026",
            "d5731562da2b42038f85346ab82f77fe",
            "e0c0da8fdb76400689fad075c71cff88",
            "8b94770b08ec46a0b0b1f4c85e060834",
            "761954ba0c4c4a3980e2dd2213baffba",
            "a82d47979ec04b87968a4419f4437d90",
            "6b9d5b786e224f7b88814d5b59a07626",
            "c597d6313567430fabb467c988cdb21c",
            "d78290e7d2ad45cd807bde15114a2ca9",
            "124e5cd1fc9949959aa0b141085ee20e",
            "81fb0864a5b04409b56effcafebf1c64",
            "cb47dd2ce8014eb58f4e296bec27af26",
            "49842cb86fcf4af79edd096246d681a0",
            "1c1b70fab836411c8a66b24d30436471",
            "fd9459fd9a4644a9a060b475fe0760e7",
            "4b25fbccc582426db777519f22e996e2",
            "baa874831fe44a6abd3eb4a6ad867c20",
            "5d1ffbc825ea40399eb02bd0f0f38614",
            "2f89cd5a076d42ffa879703a940f0d85",
            "b84c832cda0e4c25bff4264f3b3d97d2",
            "e0db7a65fe914e37a8c47e598ea8028d",
            "42d2cc1c329a4d2b802ff67b886a6832",
            "e92c9331103240f19f0edefaa2a9ff74",
            "79becae11c7b4d0e98504e4513bfb3a4"
          ]
        },
        "id": "zbpyQksvuw6c",
        "outputId": "c029887b-0b3a-49f1-cac7-596d5c4d9c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fe1bc3e9adc4d23a68b70c58fe6247b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d23b122aaa474270842c0840ab7c4777"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0c0da8fdb76400689fad075c71cff88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c1b70fab836411c8a66b24d30436471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
            "Please update transformers, TRL and unsloth via:\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    # model_name = \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_hNjiv6uw6d",
        "outputId": "81b2d2d2-e0f5-4ef6-dc72-9ddb6bc4d12f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.10.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9KgTPrPtuw6d"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsrNxEANuw6d"
      },
      "source": [
        "## Get dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ScHEQ1xIuw6e",
        "outputId": "c5425528-741e-4371-ed01-654fdf9c37cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "737ea73732244e7a94a5e8071c8608e0",
            "c9017975696d492e9db470798f0e3627",
            "6098e5b0a39a4f01b1063a6c90077100",
            "adba86cc77914b9480609e5b0a93096f",
            "d17b7b71026041568a597b070ca730c5",
            "315ed1fe1b334b0886fb99d1c7a20227",
            "eb367f3300704e0e9e2a33cd076d6e29",
            "0faba8519796407f9655122e51b37e94",
            "cdb4dc760de14ccaaf48be1fc7502a39",
            "b8e3f5007d8447ab9f2dea2eb5125d2f",
            "7fc6ff986e52478289a4419fcda0caa4",
            "88987476d40a4ea58d8af6f4f66c07be",
            "1c4821e2c35648ce8151a7078578c321",
            "d2da8e7913a04894990837a8cc6961ac",
            "4913f3d40c8c4b12a18b8652638baa65",
            "dcbb82af78d940e3ba33dc58c8c41172",
            "ae00d38f77354ba78e045e57e8a1d318",
            "413016d270974791805775de854728b7",
            "e26809446a594ee3a2d1459ba3211f8f",
            "dde069443f5f4ed580fe52f0cb6354be",
            "917feae1af8646c4803e1c290e896661",
            "7e6511ed0d0b40598a814a3d827d8d65",
            "7975edf4ad2d497a88ef62428bc2761e",
            "c96bd7529d994245bc40e9fa2c45096a",
            "55cfcc933fa44945ac90141a8ccfdaa7",
            "02c552ae7f4e4e0aa775edaf30475ae3",
            "79feda4d3f1b49c6af345e5754041fa3",
            "787f649ef6914d04a55f6538d5032460",
            "0a2dfa67bdb24ae4976d280fcd244e97",
            "341cda6ecbe44e0b858cd9f9a8d0acce",
            "625881c0b248489188c189ba40221507",
            "ba536ba0fd3344a39c46ebb1468b6b9b",
            "90b67587a4d74dada6337267ba35e4fd"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "737ea73732244e7a94a5e8071c8608e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/191k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88987476d40a4ea58d8af6f4f66c07be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/209 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7975edf4ad2d497a88ef62428bc2761e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset_finetune = load_dataset(\n",
        "    \"CPSC532/arxiv_qa_data\",\n",
        "    name=FINETUNING_DATASET_NAME,\n",
        "    split=\"train\",\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNPyjibDuw6e",
        "outputId": "e6b4ab04-e020-49b0-f2c6-069805a1c274"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'source'],\n",
              "    num_rows: 209\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset_finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "bWmiW2KHuw6e",
        "outputId": "dfbc8778-5aac-43f6-a5ea-a66fe1c59b88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is the main contribution of the paper 'Taming Transformers for High-Resolution Image Synthesis' in the context of image synthesis?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "dataset_finetune['question'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "G2ajkNV_uw6f",
        "outputId": "73538aec-3a28-4d32-927a-82c1a10cd407"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The main contribution of the paper \"Taming Transformers for High-Resolution Image Synthesis\" is the development of a novel approach that combines the strengths of convolutional neural networks (CNNs) and transformers to enable the synthesis of high-resolution images, specifically in the megapixel range. The authors propose a two-stage model where:\\n\\n1. **Learning a Context-Rich Codebook**: They first utilize a convolutional model to learn a discrete codebook of context-rich visual parts. This step leverages the inductive biases of CNNs, which are effective at capturing local structures in images. The learned codebook allows for a more efficient representation of images, reducing the complexity associated with directly modeling high-resolution images pixel by pixel.\\n\\n2. **Modeling Global Compositions with Transformers**: In the second stage, the authors employ a transformer architecture to model the global compositions of these visual parts. The transformer is adept at capturing long-range interactions, which is crucial for generating coherent and realistic high-resolution images. The approach allows for conditional synthesis, where both non-spatial information (like object classes) and spatial information (like segmentations) can guide the image generation process.\\n\\nThe paper demonstrates that this combined approach not only retains the advantages of transformers—such as their expressivity and ability to model complex relationships—but also addresses the computational challenges associated with high-resolution image synthesis. The authors report state-of-the-art results in semantically-guided synthesis of megapixel images, showcasing the effectiveness of their method compared to previous autoregressive models.\\n\\nIn summary, the key contributions are the integration of CNNs and transformers for efficient high-resolution image synthesis and the introduction of a perceptually rich codebook that enhances the quality and coherence of generated images.\\n\\nSource: Esser, P., Rombach, R., & Ommer, B. (2023). Taming Transformers for High-Resolution Image Synthesis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "dataset_finetune['answer'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1JNeUeduw6f"
      },
      "source": [
        "## Convert dataset to messages format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VmjwsgvDuw6f"
      },
      "outputs": [],
      "source": [
        "def convert_to_messages_format(example):\n",
        "    return [\n",
        "        {\"role\": \"user\", \"content\": example['question']},\n",
        "        {\"role\": \"assistant\", \"content\": example['answer']},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "g2Y3xb2Euw6f",
        "outputId": "1eba138d-62e9-435e-81ff-db171e639a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "65664df0ef3b4daeaa47e488caaf2607",
            "33e171c114e64b60aab01d772342b149",
            "afcb5de6e9ff4d9e96f6df03c9743b0e",
            "8ac11e8964914775b3895e200274cd9d",
            "ce26e89ab3af4e2dbd7aec98007a16d1",
            "0756c79c1813440bb8331b354ccafdca",
            "f17f2ec7f84d48a483bf467ee401705d",
            "cf82813d74074b8b9349ad52a58b14bf",
            "16cf8d222e2e4f948c0e7b277d7b4dc7",
            "566ce50f48924eb59eca56ed37d7f3b0",
            "e7af3681748f4b858a491bfbc6c955ff"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/209 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65664df0ef3b4daeaa47e488caaf2607"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset_finetune = dataset_finetune.map(\n",
        "    lambda x: {\n",
        "        'conversations' : convert_to_messages_format(x)\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FxM4PRoauw6f",
        "outputId": "5e430835-1d20-434f-ce44-c8c0e66290d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a1701b7cfe604b8da5ced84176913c9a",
            "65fadd0101e9445ba882a01b24953006",
            "d797090887ba49c4add2b0b43ea38f1b",
            "04a3fec084e343b88328ef137a81862b",
            "c8def0001b5444a0b45a1fd01f5e4bd2",
            "8c69f5d0409941ab9d41f33ab2ea5f0e",
            "1834b3de7ae74b27992275bc76cb6af0",
            "af36859ffc264ff69893e4b005a6d8c3",
            "a9e826da72384b05ae7de5d357311c16",
            "918c826e337d45e698f16dd7d942bb4c",
            "fb77710312a64f619f123a86bd1e599a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/209 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1701b7cfe604b8da5ced84176913c9a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset_finetune = dataset_finetune.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "UE4KL4gpuw6g",
        "outputId": "9164b51d-b038-47cc-e69f-9b7c83671fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the main contribution of the paper \\'Taming Transformers for High-Resolution Image Synthesis\\' in the context of image synthesis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe main contribution of the paper \"Taming Transformers for High-Resolution Image Synthesis\" is the development of a novel approach that combines the strengths of convolutional neural networks (CNNs) and transformers to enable the synthesis of high-resolution images, specifically in the megapixel range. The authors propose a two-stage model where:\\n\\n1. **Learning a Context-Rich Codebook**: They first utilize a convolutional model to learn a discrete codebook of context-rich visual parts. This step leverages the inductive biases of CNNs, which are effective at capturing local structures in images. The learned codebook allows for a more efficient representation of images, reducing the complexity associated with directly modeling high-resolution images pixel by pixel.\\n\\n2. **Modeling Global Compositions with Transformers**: In the second stage, the authors employ a transformer architecture to model the global compositions of these visual parts. The transformer is adept at capturing long-range interactions, which is crucial for generating coherent and realistic high-resolution images. The approach allows for conditional synthesis, where both non-spatial information (like object classes) and spatial information (like segmentations) can guide the image generation process.\\n\\nThe paper demonstrates that this combined approach not only retains the advantages of transformers—such as their expressivity and ability to model complex relationships—but also addresses the computational challenges associated with high-resolution image synthesis. The authors report state-of-the-art results in semantically-guided synthesis of megapixel images, showcasing the effectiveness of their method compared to previous autoregressive models.\\n\\nIn summary, the key contributions are the integration of CNNs and transformers for efficient high-resolution image synthesis and the introduction of a perceptually rich codebook that enhances the quality and coherence of generated images.\\n\\nSource: Esser, P., Rombach, R., & Ommer, B. (2023). Taming Transformers for High-Resolution Image Synthesis.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "dataset_finetune['text'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aysQr1W4uw6g"
      },
      "source": [
        "## Set Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "22E9pLsnuw6g",
        "outputId": "a490b346-cea7-48a0-8695-08ac745d8d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "59c3801c6e684b99a1563af49f7cc43f",
            "63b5defe17f34ac69f13a8cc274df900",
            "21df4cbf56354a4485bd29cc0714204b",
            "cc7e1f3d7b334eadb084e75a5832cc83",
            "58ef502d013740e883b9762d220131cc",
            "3834954b62b74711a002fdd36d4af4bc",
            "bcc48745f85e45ad96f7cf5dbba0bcc2",
            "c5d58c1af0df4f9390164ba352f5ca28",
            "addbcaf2fe9f4fb09d95e1d4c695d96b",
            "cc719852a4ee4b46a85f0f219d9de712",
            "0d83779ed4344074aac5f20323fbad5f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/209 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59c3801c6e684b99a1563af49f7cc43f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset_finetune,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 1,  # Affects memory usage\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2, # Affects memory usage\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 20, # Set this for 1 full training run.\n",
        "        # max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMbXl2BIuw6g"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs. Look into this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ztgyBsIwuw6g",
        "outputId": "1e1c07ca-38ca-4f8c-fbb3-e060de4f6367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b9a4c17da78349c29a0b72aaac331694",
            "933497998cc9430287521369de07d5a9",
            "d13699d706e244e1b5cad4a463eea3b4",
            "247b70e3c8ef453ca2b1cc4029150302",
            "d199b8da76cc42c29c0978c171d8f858",
            "66c8b8a3da7d474dbd2fc263209965d2",
            "52eedd207da546cab1779a26c9a6392a",
            "0602c8209d494f0dacb4de7ce751f099",
            "10cce9d020b14c7f8063cc5603f63db0",
            "602d6717c29c4dd3aea3894662ae2d6b",
            "83fb4b60f1bd42978761dda7550b2f27"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/209 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9a4c17da78349c29a0b72aaac331694"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "ClC-xQP4uw6g",
        "outputId": "2b6c7e0e-a282-444e-abc4-1dae1fe644ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the main contribution of the paper \\'Taming Transformers for High-Resolution Image Synthesis\\' in the context of image synthesis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe main contribution of the paper \"Taming Transformers for High-Resolution Image Synthesis\" is the development of a novel approach that combines the strengths of convolutional neural networks (CNNs) and transformers to enable the synthesis of high-resolution images, specifically in the megapixel range. The authors propose a two-stage model where:\\n\\n1. **Learning a Context-Rich Codebook**: They first utilize a convolutional model to learn a discrete codebook of context-rich visual parts. This step leverages the inductive biases of CNNs, which are effective at capturing local structures in images. The learned codebook allows for a more efficient representation of images, reducing the complexity associated with directly modeling high-resolution images pixel by pixel.\\n\\n2. **Modeling Global Compositions with Transformers**: In the second stage, the authors employ a transformer architecture to model the global compositions of these visual parts. The transformer is adept at capturing long-range interactions, which is crucial for generating coherent and realistic high-resolution images. The approach allows for conditional synthesis, where both non-spatial information (like object classes) and spatial information (like segmentations) can guide the image generation process.\\n\\nThe paper demonstrates that this combined approach not only retains the advantages of transformers—such as their expressivity and ability to model complex relationships—but also addresses the computational challenges associated with high-resolution image synthesis. The authors report state-of-the-art results in semantically-guided synthesis of megapixel images, showcasing the effectiveness of their method compared to previous autoregressive models.\\n\\nIn summary, the key contributions are the integration of CNNs and transformers for efficient high-resolution image synthesis and the introduction of a perceptually rich codebook that enhances the quality and coherence of generated images.\\n\\nSource: Esser, P., Rombach, R., & Ommer, B. (2023). Taming Transformers for High-Resolution Image Synthesis.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[0][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "1s_BgcwMuw6g",
        "outputId": "88f30a66-581b-4fc5-bf49-94daa62cb309"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                 \\n\\nModeling long-range interactions in high-resolution images is crucial for several reasons, as highlighted in the paper \"Taming Transformers for High-Resolution Image Synthesis\":\\n\\n1. **Global Composition Understanding**: High-resolution images consist of complex structures and patterns that span across large areas. To generate images that are not only locally realistic but also globally consistent, it is essential to understand how different parts of the image relate to one another. The paper emphasizes that high-resolution image synthesis requires a model that comprehends the global composition of images, enabling it to generate coherent and contextually appropriate visuals.\\n\\n2. **Expressivity of Transformers**: Transformers are designed to learn complex relationships among inputs without a built-in bias towards locality, which allows them to capture long-range dependencies effectively. This expressivity is particularly beneficial in high-resolution image synthesis, where the relationships between distant pixels or image constituents can significantly influence the overall appearance and coherence of the generated image.\\n\\n3. **Reduction of Computational Complexity**: The paper discusses the challenge of computational costs associated with transformers, which increase quadratically with the sequence length (i.e., the number of pixels in high-resolution images). By modeling long-range interactions efficiently, the authors propose a method that combines convolutional neural networks (CNNs) with transformers. This hybrid approach allows for the effective modeling of global interactions while managing computational demands, making it feasible to synthesize high-resolution images.\\n\\n4. **Conditioning on Spatial Information**: The ability to model long-range interactions also facilitates the incorporation of conditioning information, such as object classes or spatial layouts, into the image generation process. This capability allows for more controlled and semantically guided synthesis, where the generated images can be tailored to specific requirements or contexts.\\n\\n5. **Perceptual Quality**: The paper highlights that capturing long-range interactions is essential for maintaining high perceptual quality in the generated images. By ensuring that the model can account for the relationships between different parts of the image, the resulting images are more likely to be visually appealing and realistic.\\n\\nIn summary, modeling long-range interactions is vital for achieving high-resolution image synthesis that is coherent, contextually relevant, and perceptually high-quality, while also addressing the computational challenges associated with processing large images.\\n\\nSource: \"Taming Transformers for High-Resolution Image Synthesis\" by Patrick Esser, Robin Rombach, and Björn Ommer.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-k53HMbuw6h",
        "outputId": "26f21fea-0742-4d23-deca-63228d6b8e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.564 GB.\n",
            "4.943 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "nXzbNdQk_wtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOPemaS5uw6h",
        "outputId": "22040288-e3d9-4b01-e104-192e1e766e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 209 | Num Epochs = 20\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 520\n",
            " \"-____-\"     Number of trainable parameters = 194,510,848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='520' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [520/520 13:33, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.412500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.629000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.327000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.412600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.180200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.215500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.172600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.185200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.157300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.252600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.086900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.962200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.114200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.120500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.124100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.219100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.050900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.027700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.883000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.173200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.936700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.789600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.546700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.692500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.716100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.646900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.755100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.664200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.510700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.724100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.598200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.441100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.724800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.640100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.637100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.642000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.488400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.638100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.668800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.549700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.713100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.525500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.579300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.666600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.479900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.354200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.318600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.289400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.338600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.243400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.239900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.409800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.246300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.366300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.221100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.303200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.285600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.208600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.279400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.247500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.290900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.263900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.321500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.254500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.108800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.149400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.113800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.123300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.181000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.129100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.136900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.154900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.138000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.135400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.123800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.143600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.134900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.145600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.115400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.175400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.149700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.058400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.078600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.062000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.068000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.060700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.052100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.062400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.078600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.078000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.094000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.024700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.054100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.048300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.051300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.046500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.027400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.048600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.028100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.036400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.052000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.049200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.038100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.020200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.018200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.046300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.013800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.025500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.018100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.021300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.035100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.023800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.019900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.017600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.014400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.020500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.012800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.019000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.015900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.008300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.010100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.019200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.017100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.021300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.006200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.009600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>0.093100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>0.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.025100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.021600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.004600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>301</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>302</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>304</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>307</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>308</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>311</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>313</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>314</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>316</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>317</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>319</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>322</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>323</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>326</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>328</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>329</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>331</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>332</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>334</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>337</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>338</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>341</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>343</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>344</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>346</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>347</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>348</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>349</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>352</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>353</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>354</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>356</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>358</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>359</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>361</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>362</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>363</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>364</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>366</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>367</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>368</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>369</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>371</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>373</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>374</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>376</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>377</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>378</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>379</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>381</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>382</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>383</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>384</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>386</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>387</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>388</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>389</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>391</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>392</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>393</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>394</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>396</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>397</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>398</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>399</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>401</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>402</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>403</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>404</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>406</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>407</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>409</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>411</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>412</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>413</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>414</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>416</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>417</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>418</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>419</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>421</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>422</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>423</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>424</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>426</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>427</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>428</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>429</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>431</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>433</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>434</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>436</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>437</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>438</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>439</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>441</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>442</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>443</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>444</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>446</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>447</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>448</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>449</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>451</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>452</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>453</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>454</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>456</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>457</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>458</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>459</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>461</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>462</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>463</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>464</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>466</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>467</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>469</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>471</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>472</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>473</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>474</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>476</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>477</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>478</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>479</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>481</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>482</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>483</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>484</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>486</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>487</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>488</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>489</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>491</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>492</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>493</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>494</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>496</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>497</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>498</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>499</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>501</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>502</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>503</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>504</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>505</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>506</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>507</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>508</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>511</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>512</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>513</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>514</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>515</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>516</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>517</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>518</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>519</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ph91r3-uw6h",
        "outputId": "40f74014-5443-43ba-e3ad-92af378a59af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "821.0797 seconds used for training.\n",
            "13.68 minutes used for training.\n",
            "Peak reserved memory = 7.26 GB.\n",
            "Peak reserved memory for training = 2.317 GB.\n",
            "Peak reserved memory % of max memory = 18.35 %.\n",
            "Peak reserved memory for training % of max memory = 5.856 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_17zqUsuw6h"
      },
      "source": [
        "## Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7bVoC26xuw6h"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "def get_response(user_query):\n",
        "    messages = [\n",
        "    {\"role\": \"user\", \"content\": user_query},\n",
        "    ]\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize = True,\n",
        "        add_generation_prompt = True, # Must add for generation\n",
        "        return_tensors = \"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
        "                            temperature = 1.5, min_p = 0.1)\n",
        "    return tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "HTYSzXcJuw6h",
        "outputId": "a53af4e0-cea8-454c-8a50-2a346e156312"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is the main contribution of the paper 'Taming Transformers for High-Resolution Image Synthesis' in the context of image synthesis?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset_finetune['question'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYV5H1LEuw6h"
      },
      "source": [
        "Need to investigate how changing the question affects responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNxBufzGuw6h",
        "outputId": "91cbbfb8-140a-4fb1-f6d5-a344b5cd2191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The main contribution of the paper \"Taming Transformers for High-Resolution Image Synthesis\" is the development of a novel approach that combines the strengths of convolutional neural networks (CNNs) and transformers to enable the synthesis of high-resolution images, specifically in the megapixel range. The authors propose a two-stage model where\n"
          ]
        }
      ],
      "source": [
        "resp = get_response(dataset_finetune['question'][0])\n",
        "print(resp[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNMdQqDSuw6h"
      },
      "source": [
        "## Save to HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03e997ceb2e742a980fab26374e51ccd",
            "0a6a6203ff4e441596283b5a649f3566",
            "b000c97cab6b43a084ba83c26819a11f",
            "825f6238bb524eac80e980bbcc1e7c53",
            "04085d9328404d7785a445ccbdf9bc40",
            "f0bc66d28e4d4818bd3c4c6ed78bec75",
            "c110e58ec4a44535994b1a9ee55608b1",
            "6edfa3ebfeb9409c90ab6c5acf82b467",
            "8685d791b6de44ef955d43b3920da1b7",
            "19ace759f2854b278018e9b0ad3cb2cb",
            "3772a77e3b0e4c7bb0ed6a75f2a3da4d",
            "e40ccbd8e3c7452189d559703b65bfc4",
            "0965bf189e5c453da15cc342ff567b5a",
            "e3df2d556cc6442f841cf1e864c41a97",
            "5d4ef03ade4c48008fbcba81f45af4f4",
            "24d8a9ee003449ca92b2d0c362cfe69c",
            "30e12a5a12fe4ff3a42b29f9f19e44aa",
            "be6ad0d1497f4d8b8d0463c672c6eef9",
            "67e768bb48724ba59342c9e92ac76f68",
            "c1580136dad2490fb79f4a406bc68e8a",
            "4fff89b5d9fd444485b3288b3dd5ccff",
            "67e2d7a3c19c4b77893d86b8657c216f",
            "789ae18eb363419eaa4f97dfed170531",
            "275578403bde4d40a32a15e8be81491c",
            "c362a17171164a208d98f8f8d09d4843",
            "f739984d782f4c5b93f7ee7b0de2546e",
            "63d5b7750fa24822b8c2f7eb3fefe77f",
            "034ff78731844d01b1de0b2bf501fe95",
            "3d57abb2772b49388b6765e11113fee0",
            "ac698617c94a4f099ef834b8800b5977",
            "52906ccfb4ca4e6a8c7bccc089b7b43d",
            "7e267e5fcd6d456e81390f8a9b55730f",
            "0219937e56d043ae9ecab745edd5b680"
          ]
        },
        "id": "DKIN4QnLuw6h",
        "outputId": "e801d621-f8af-4fdc-c083-cdc7afc0a119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 2.2G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 60.04 out of 83.48 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 40.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at CPSC532/finetuned_model_2024OCT24 into bf16 GGUF format.\n",
            "The output location will be /content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: finetuned_model_2024OCT24\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {3072, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 24\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 32\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128004\n",
            "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 July 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\n",
            "\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\n",
            "\n",
            "\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\n",
            "\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\n",
            "\n",
            "\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content'] %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\n",
            "\n",
            "\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}\n",
            "{%- endif %}\n",
            "\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf: n_tensors = 255, total_size = 6.4G\n",
            "Writing: 100%|██████████| 6.43G/6.43G [00:29<00:00, 219Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3974 (958367bf)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf' to '/content/CPSC532/finetuned_model_2024OCT24/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 3B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 28\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 24\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   58 tensors\n",
            "llama_model_loader: - type bf16:  197 tensors\n",
            "[   1/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =   bf16, converting to q6_K .. size =   751.50 MiB ->   308.23 MiB\n",
            "[   3/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   4/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[   5/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[   6/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[   7/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   8/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[   9/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  10/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  11/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  12/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  13/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  14/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  15/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  16/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  17/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  18/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  19/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  20/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  21/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  22/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  23/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  24/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  25/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  26/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  27/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  28/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  29/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  30/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  31/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  32/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  33/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  34/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  35/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  36/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  37/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  38/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  39/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  40/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  41/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  42/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  43/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  44/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  45/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  46/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  47/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  48/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  49/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  50/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  51/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  52/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  53/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  54/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  55/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  56/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  57/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  58/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  59/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  60/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  61/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  62/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  63/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  64/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  65/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  66/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  67/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  68/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  69/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  70/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  71/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  72/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  73/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  74/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  75/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  76/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  77/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  78/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  79/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  80/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  81/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  82/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  83/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  84/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  85/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  86/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  87/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  88/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  89/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  90/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  91/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  92/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  93/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  94/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  95/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  96/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  97/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  98/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  99/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 100/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 101/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 102/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 103/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 104/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 105/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 106/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 107/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 108/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 109/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 110/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 111/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 112/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 113/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 114/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 115/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 116/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 117/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 118/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 119/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 120/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 121/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 122/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 123/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 124/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 125/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 126/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 127/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 128/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 129/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 130/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 131/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 132/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 133/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 134/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 135/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 136/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 137/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 138/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 139/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 140/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 141/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 142/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 143/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 144/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 145/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 146/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 147/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 148/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 149/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 150/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 151/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 152/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 153/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 154/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 155/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 156/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 157/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 158/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 159/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 160/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 161/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 162/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 163/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 164/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 165/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 166/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 167/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 168/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 169/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 170/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 171/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 172/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 173/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 174/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 175/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 176/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 177/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 178/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 179/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 180/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 181/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 182/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 183/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 184/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 185/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 186/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 187/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 188/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 189/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 190/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 192/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 193/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 194/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 195/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 196/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 197/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 198/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 199/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 200/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 201/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 202/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 203/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 204/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 205/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 206/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 207/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 208/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 209/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 210/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 211/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 212/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 213/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 214/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 215/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 216/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 217/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 218/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 219/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 220/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 221/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 222/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 223/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 224/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 225/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 226/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 227/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 228/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 229/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 230/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 231/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 232/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 233/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 234/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 235/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 236/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 237/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 238/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 239/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 240/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 241/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 242/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 243/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 244/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 245/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 246/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 247/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 248/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 249/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 250/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 251/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 252/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 253/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 254/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 255/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "llama_model_quantize_internal: model size  =  6128.17 MB\n",
            "llama_model_quantize_internal: quant size  =  1918.35 MB\n",
            "\n",
            "main: quantize time = 56588.03 ms\n",
            "main:    total time = 56588.03 ms\n",
            "Unsloth: Conversion completed! Output location: /content/CPSC532/finetuned_model_2024OCT24/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q8_0. This will take 20 minutes...\n",
            "main: build = 3974 (958367bf)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf' to '/content/CPSC532/finetuned_model_2024OCT24/unsloth.Q8_0.gguf' as Q8_0 using 24 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 3B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 28\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 24\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   58 tensors\n",
            "llama_model_loader: - type bf16:  197 tensors\n",
            "[   1/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =   bf16, converting to q8_0 .. size =   751.50 MiB ->   399.23 MiB\n",
            "[   3/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   4/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[   5/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[   6/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[   7/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   8/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[   9/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  10/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  11/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  12/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  13/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  14/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  15/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  16/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  17/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  18/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  19/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  20/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  21/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  22/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  23/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  24/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  25/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  26/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  27/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  28/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  29/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  30/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  31/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  32/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  33/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  34/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  35/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  36/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  37/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  38/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  39/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  40/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  41/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  42/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  43/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  44/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  45/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  46/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  47/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  48/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  49/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  50/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  51/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  52/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  53/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  54/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  55/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  56/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  57/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  58/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  59/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  60/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  61/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  62/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  63/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  64/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  65/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  66/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  67/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  68/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  69/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  70/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  71/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  72/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  73/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  74/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  75/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  76/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  77/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  78/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  79/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  80/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  81/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  82/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  83/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  84/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  85/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  86/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  87/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  88/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  89/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  90/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  91/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[  92/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  93/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  94/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  95/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  96/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[  97/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  98/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[  99/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 100/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 101/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 102/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 103/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 104/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 105/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 106/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 107/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 108/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 109/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 110/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 111/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 112/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 113/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 114/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 115/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 116/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 117/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 118/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 119/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 120/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 121/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 122/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 123/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 124/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 125/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 126/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 127/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 128/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 129/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 130/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 131/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 132/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 133/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 134/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 135/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 136/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 137/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 138/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 139/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 140/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 141/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 142/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 143/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 144/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 145/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 146/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 147/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 148/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 149/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 150/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 151/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 152/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 153/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 154/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 155/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 156/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 157/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 158/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 159/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 160/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 161/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 162/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 163/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 164/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 165/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 166/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 167/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 168/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 169/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 170/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 171/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 172/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 173/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 174/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 175/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 176/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 177/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 178/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 179/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 180/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 181/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 182/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 183/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 184/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 185/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 186/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 187/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 188/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 189/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 190/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 192/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 193/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 194/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 195/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 196/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 197/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 198/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 199/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 200/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 201/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 202/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 203/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 204/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 205/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 206/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 207/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 208/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 209/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 210/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 211/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 212/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 213/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 214/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 215/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 216/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 217/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 218/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 219/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 220/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 221/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 222/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 223/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 224/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 225/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 226/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 227/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 228/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 229/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 230/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 231/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 232/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 233/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 234/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 235/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 236/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 237/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 238/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 239/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 240/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 241/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 242/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 243/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 244/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 245/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 246/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 247/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 248/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 249/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
            "[ 250/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 251/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 252/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 253/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
            "[ 254/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
            "[ 255/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "llama_model_quantize_internal: model size  =  6128.17 MB\n",
            "llama_model_quantize_internal: quant size  =  3255.90 MB\n",
            "\n",
            "main: quantize time =  8653.18 ms\n",
            "main:    total time =  8653.18 ms\n",
            "Unsloth: Conversion completed! Output location: /content/CPSC532/finetuned_model_2024OCT24/unsloth.Q8_0.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This will take 20 minutes...\n",
            "main: build = 3974 (958367bf)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf' to '/content/CPSC532/finetuned_model_2024OCT24/unsloth.Q5_K_M.gguf' as Q5_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /content/CPSC532/finetuned_model_2024OCT24/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 3B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 28\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 24\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   58 tensors\n",
            "llama_model_loader: - type bf16:  197 tensors\n",
            "[   1/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =   bf16, converting to q6_K .. size =   751.50 MiB ->   308.23 MiB\n",
            "[   3/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   4/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[   5/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[   6/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[   7/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   8/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[   9/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  10/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  11/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  12/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  13/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  14/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  15/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  16/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  17/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  18/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  19/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  20/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  21/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  22/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  23/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  24/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  25/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  26/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  27/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  28/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  29/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  30/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  31/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  32/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  33/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  34/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  35/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  36/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  37/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  38/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  39/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  40/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  41/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  42/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  43/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  44/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  45/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  46/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  47/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  48/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  49/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  50/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  51/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  52/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  53/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  54/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  55/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  56/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  57/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  58/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  59/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  60/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  61/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  62/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  63/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  64/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  65/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  66/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  67/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  68/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  69/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  70/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  71/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  72/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  73/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  74/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  75/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  76/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  77/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  78/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  79/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  80/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  81/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  82/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  83/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  84/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  85/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  86/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  87/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  88/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  89/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  90/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  91/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[  92/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  93/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  94/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  95/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  96/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[  97/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  98/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[  99/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 100/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 101/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 102/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 103/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 104/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 105/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 106/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 107/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 108/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 109/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 110/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 111/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 112/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 113/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 114/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 115/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 116/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 117/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 118/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 119/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 120/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 121/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 122/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 123/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 124/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 125/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 126/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 127/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 128/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 129/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 130/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 131/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 132/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 133/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 134/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 135/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 136/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 137/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 138/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 139/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 140/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 141/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 142/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 143/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 144/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 145/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 146/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 147/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 148/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 149/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 150/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 151/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 152/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 153/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 154/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 155/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 156/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 157/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 158/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 159/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 160/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 161/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 162/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 163/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 164/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 165/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 166/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 167/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 168/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 169/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 170/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 171/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 172/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 173/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 174/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 175/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 176/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 177/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 178/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 179/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 180/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 181/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 182/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 183/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 184/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 185/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 186/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 187/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 188/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 189/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 190/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 192/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 193/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 194/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 195/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 196/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 197/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 198/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 199/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 200/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 201/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 202/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 203/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 204/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 205/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 206/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 207/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 208/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 209/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 210/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 211/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 212/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 213/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 214/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 215/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 216/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 217/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 218/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 219/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 220/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 221/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 222/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 223/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 224/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 225/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 226/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 227/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 228/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 229/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 230/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 231/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 232/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 233/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 234/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 235/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 236/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 237/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 238/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 239/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 240/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 241/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 242/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 243/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 244/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 245/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 246/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 247/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 248/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 249/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
            "[ 250/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 251/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
            "[ 252/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 253/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
            "[ 254/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 255/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "llama_model_quantize_internal: model size  =  6128.17 MB\n",
            "llama_model_quantize_internal: quant size  =  2207.10 MB\n",
            "\n",
            "main: quantize time = 46033.64 ms\n",
            "main:    total time = 46033.64 ms\n",
            "Unsloth: Conversion completed! Output location: /content/CPSC532/finetuned_model_2024OCT24/unsloth.Q5_K_M.gguf\n",
            "Unsloth: Saved Ollama Modelfile to CPSC532/finetuned_model_2024OCT24/Modelfile\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03e997ceb2e742a980fab26374e51ccd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/CPSC532/finetuned_model_2024OCT24\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q8_0.gguf:   0%|          | 0.00/3.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e40ccbd8e3c7452189d559703b65bfc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/CPSC532/finetuned_model_2024OCT24\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q5_K_M.gguf:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "789ae18eb363419eaa4f97dfed170531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/CPSC532/finetuned_model_2024OCT24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Ollama Modelfile to https://huggingface.co/CPSC532/finetuned_model_2024OCT24\n"
          ]
        }
      ],
      "source": [
        "model.push_to_hub_gguf(\n",
        "        f\"CPSC532/{OUTPUT_MODEL_NAME}\",\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\"],\n",
        "        token = HF_TOKEN\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fe1bc3e9adc4d23a68b70c58fe6247b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f045515f2e948afbed1eaa42a863e64",
              "IPY_MODEL_b5737cac09f04c82ba77a6743996bb22",
              "IPY_MODEL_2e55562e92f44f998b2db708331bc578"
            ],
            "layout": "IPY_MODEL_5eba2ef7021a41dfb01521f24b549442"
          }
        },
        "5f045515f2e948afbed1eaa42a863e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e329f138556458688fdb827ad56e89d",
            "placeholder": "​",
            "style": "IPY_MODEL_3661952fe0a9423288c424ab545a18b9",
            "value": "generation_config.json: 100%"
          }
        },
        "b5737cac09f04c82ba77a6743996bb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979bd94798e84360bdea1047b6f82714",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcf163bcddcf4722bb55efb9631e031c",
            "value": 184
          }
        },
        "2e55562e92f44f998b2db708331bc578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066097e8a41747dbb200f56c191911e3",
            "placeholder": "​",
            "style": "IPY_MODEL_d12d8859fe08497c8960c4615d738286",
            "value": " 184/184 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "5eba2ef7021a41dfb01521f24b549442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e329f138556458688fdb827ad56e89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3661952fe0a9423288c424ab545a18b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979bd94798e84360bdea1047b6f82714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf163bcddcf4722bb55efb9631e031c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "066097e8a41747dbb200f56c191911e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12d8859fe08497c8960c4615d738286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d23b122aaa474270842c0840ab7c4777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52c2e1ed3a1a4f2e9bbb549fcf3e84d4",
              "IPY_MODEL_cc71bea3bd014085bc0d18db7cb87c90",
              "IPY_MODEL_a73bfefd43de419da5fac7c6c12e63e4"
            ],
            "layout": "IPY_MODEL_cc266b672f2040c097abea42b60a1180"
          }
        },
        "52c2e1ed3a1a4f2e9bbb549fcf3e84d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39729ca458e145e6a019637489652c54",
            "placeholder": "​",
            "style": "IPY_MODEL_819c5a0a37a249cd9e1905767eecb2ef",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cc71bea3bd014085bc0d18db7cb87c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b37909e1bc44e3babbd132cecadcbf7",
            "max": 54598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_661f3a1eac7b4bc3ae44e3a250aa7871",
            "value": 54598
          }
        },
        "a73bfefd43de419da5fac7c6c12e63e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d429d427352e446b8b2085cd313ac026",
            "placeholder": "​",
            "style": "IPY_MODEL_d5731562da2b42038f85346ab82f77fe",
            "value": " 54.6k/54.6k [00:00&lt;00:00, 3.55MB/s]"
          }
        },
        "cc266b672f2040c097abea42b60a1180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39729ca458e145e6a019637489652c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819c5a0a37a249cd9e1905767eecb2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b37909e1bc44e3babbd132cecadcbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661f3a1eac7b4bc3ae44e3a250aa7871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d429d427352e446b8b2085cd313ac026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5731562da2b42038f85346ab82f77fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0c0da8fdb76400689fad075c71cff88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b94770b08ec46a0b0b1f4c85e060834",
              "IPY_MODEL_761954ba0c4c4a3980e2dd2213baffba",
              "IPY_MODEL_a82d47979ec04b87968a4419f4437d90"
            ],
            "layout": "IPY_MODEL_6b9d5b786e224f7b88814d5b59a07626"
          }
        },
        "8b94770b08ec46a0b0b1f4c85e060834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c597d6313567430fabb467c988cdb21c",
            "placeholder": "​",
            "style": "IPY_MODEL_d78290e7d2ad45cd807bde15114a2ca9",
            "value": "tokenizer.json: 100%"
          }
        },
        "761954ba0c4c4a3980e2dd2213baffba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124e5cd1fc9949959aa0b141085ee20e",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81fb0864a5b04409b56effcafebf1c64",
            "value": 9085657
          }
        },
        "a82d47979ec04b87968a4419f4437d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb47dd2ce8014eb58f4e296bec27af26",
            "placeholder": "​",
            "style": "IPY_MODEL_49842cb86fcf4af79edd096246d681a0",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 34.5MB/s]"
          }
        },
        "6b9d5b786e224f7b88814d5b59a07626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c597d6313567430fabb467c988cdb21c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78290e7d2ad45cd807bde15114a2ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "124e5cd1fc9949959aa0b141085ee20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81fb0864a5b04409b56effcafebf1c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb47dd2ce8014eb58f4e296bec27af26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49842cb86fcf4af79edd096246d681a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1b70fab836411c8a66b24d30436471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd9459fd9a4644a9a060b475fe0760e7",
              "IPY_MODEL_4b25fbccc582426db777519f22e996e2",
              "IPY_MODEL_baa874831fe44a6abd3eb4a6ad867c20"
            ],
            "layout": "IPY_MODEL_5d1ffbc825ea40399eb02bd0f0f38614"
          }
        },
        "fd9459fd9a4644a9a060b475fe0760e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f89cd5a076d42ffa879703a940f0d85",
            "placeholder": "​",
            "style": "IPY_MODEL_b84c832cda0e4c25bff4264f3b3d97d2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4b25fbccc582426db777519f22e996e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0db7a65fe914e37a8c47e598ea8028d",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42d2cc1c329a4d2b802ff67b886a6832",
            "value": 454
          }
        },
        "baa874831fe44a6abd3eb4a6ad867c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92c9331103240f19f0edefaa2a9ff74",
            "placeholder": "​",
            "style": "IPY_MODEL_79becae11c7b4d0e98504e4513bfb3a4",
            "value": " 454/454 [00:00&lt;00:00, 35.3kB/s]"
          }
        },
        "5d1ffbc825ea40399eb02bd0f0f38614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f89cd5a076d42ffa879703a940f0d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b84c832cda0e4c25bff4264f3b3d97d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0db7a65fe914e37a8c47e598ea8028d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d2cc1c329a4d2b802ff67b886a6832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e92c9331103240f19f0edefaa2a9ff74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79becae11c7b4d0e98504e4513bfb3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "737ea73732244e7a94a5e8071c8608e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9017975696d492e9db470798f0e3627",
              "IPY_MODEL_6098e5b0a39a4f01b1063a6c90077100",
              "IPY_MODEL_adba86cc77914b9480609e5b0a93096f"
            ],
            "layout": "IPY_MODEL_d17b7b71026041568a597b070ca730c5"
          }
        },
        "c9017975696d492e9db470798f0e3627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_315ed1fe1b334b0886fb99d1c7a20227",
            "placeholder": "​",
            "style": "IPY_MODEL_eb367f3300704e0e9e2a33cd076d6e29",
            "value": "README.md: 100%"
          }
        },
        "6098e5b0a39a4f01b1063a6c90077100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0faba8519796407f9655122e51b37e94",
            "max": 1906,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdb4dc760de14ccaaf48be1fc7502a39",
            "value": 1906
          }
        },
        "adba86cc77914b9480609e5b0a93096f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e3f5007d8447ab9f2dea2eb5125d2f",
            "placeholder": "​",
            "style": "IPY_MODEL_7fc6ff986e52478289a4419fcda0caa4",
            "value": " 1.91k/1.91k [00:00&lt;00:00, 146kB/s]"
          }
        },
        "d17b7b71026041568a597b070ca730c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315ed1fe1b334b0886fb99d1c7a20227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb367f3300704e0e9e2a33cd076d6e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0faba8519796407f9655122e51b37e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb4dc760de14ccaaf48be1fc7502a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8e3f5007d8447ab9f2dea2eb5125d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc6ff986e52478289a4419fcda0caa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88987476d40a4ea58d8af6f4f66c07be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c4821e2c35648ce8151a7078578c321",
              "IPY_MODEL_d2da8e7913a04894990837a8cc6961ac",
              "IPY_MODEL_4913f3d40c8c4b12a18b8652638baa65"
            ],
            "layout": "IPY_MODEL_dcbb82af78d940e3ba33dc58c8c41172"
          }
        },
        "1c4821e2c35648ce8151a7078578c321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae00d38f77354ba78e045e57e8a1d318",
            "placeholder": "​",
            "style": "IPY_MODEL_413016d270974791805775de854728b7",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "d2da8e7913a04894990837a8cc6961ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26809446a594ee3a2d1459ba3211f8f",
            "max": 190800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dde069443f5f4ed580fe52f0cb6354be",
            "value": 190800
          }
        },
        "4913f3d40c8c4b12a18b8652638baa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917feae1af8646c4803e1c290e896661",
            "placeholder": "​",
            "style": "IPY_MODEL_7e6511ed0d0b40598a814a3d827d8d65",
            "value": " 191k/191k [00:00&lt;00:00, 12.2MB/s]"
          }
        },
        "dcbb82af78d940e3ba33dc58c8c41172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae00d38f77354ba78e045e57e8a1d318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413016d270974791805775de854728b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e26809446a594ee3a2d1459ba3211f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde069443f5f4ed580fe52f0cb6354be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "917feae1af8646c4803e1c290e896661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e6511ed0d0b40598a814a3d827d8d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7975edf4ad2d497a88ef62428bc2761e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c96bd7529d994245bc40e9fa2c45096a",
              "IPY_MODEL_55cfcc933fa44945ac90141a8ccfdaa7",
              "IPY_MODEL_02c552ae7f4e4e0aa775edaf30475ae3"
            ],
            "layout": "IPY_MODEL_79feda4d3f1b49c6af345e5754041fa3"
          }
        },
        "c96bd7529d994245bc40e9fa2c45096a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_787f649ef6914d04a55f6538d5032460",
            "placeholder": "​",
            "style": "IPY_MODEL_0a2dfa67bdb24ae4976d280fcd244e97",
            "value": "Generating train split: 100%"
          }
        },
        "55cfcc933fa44945ac90141a8ccfdaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_341cda6ecbe44e0b858cd9f9a8d0acce",
            "max": 209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_625881c0b248489188c189ba40221507",
            "value": 209
          }
        },
        "02c552ae7f4e4e0aa775edaf30475ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba536ba0fd3344a39c46ebb1468b6b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_90b67587a4d74dada6337267ba35e4fd",
            "value": " 209/209 [00:00&lt;00:00, 4325.75 examples/s]"
          }
        },
        "79feda4d3f1b49c6af345e5754041fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "787f649ef6914d04a55f6538d5032460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2dfa67bdb24ae4976d280fcd244e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341cda6ecbe44e0b858cd9f9a8d0acce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "625881c0b248489188c189ba40221507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba536ba0fd3344a39c46ebb1468b6b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b67587a4d74dada6337267ba35e4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65664df0ef3b4daeaa47e488caaf2607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33e171c114e64b60aab01d772342b149",
              "IPY_MODEL_afcb5de6e9ff4d9e96f6df03c9743b0e",
              "IPY_MODEL_8ac11e8964914775b3895e200274cd9d"
            ],
            "layout": "IPY_MODEL_ce26e89ab3af4e2dbd7aec98007a16d1"
          }
        },
        "33e171c114e64b60aab01d772342b149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0756c79c1813440bb8331b354ccafdca",
            "placeholder": "​",
            "style": "IPY_MODEL_f17f2ec7f84d48a483bf467ee401705d",
            "value": "Map: 100%"
          }
        },
        "afcb5de6e9ff4d9e96f6df03c9743b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf82813d74074b8b9349ad52a58b14bf",
            "max": 209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16cf8d222e2e4f948c0e7b277d7b4dc7",
            "value": 209
          }
        },
        "8ac11e8964914775b3895e200274cd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566ce50f48924eb59eca56ed37d7f3b0",
            "placeholder": "​",
            "style": "IPY_MODEL_e7af3681748f4b858a491bfbc6c955ff",
            "value": " 209/209 [00:00&lt;00:00, 4235.54 examples/s]"
          }
        },
        "ce26e89ab3af4e2dbd7aec98007a16d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0756c79c1813440bb8331b354ccafdca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17f2ec7f84d48a483bf467ee401705d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf82813d74074b8b9349ad52a58b14bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16cf8d222e2e4f948c0e7b277d7b4dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "566ce50f48924eb59eca56ed37d7f3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7af3681748f4b858a491bfbc6c955ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1701b7cfe604b8da5ced84176913c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65fadd0101e9445ba882a01b24953006",
              "IPY_MODEL_d797090887ba49c4add2b0b43ea38f1b",
              "IPY_MODEL_04a3fec084e343b88328ef137a81862b"
            ],
            "layout": "IPY_MODEL_c8def0001b5444a0b45a1fd01f5e4bd2"
          }
        },
        "65fadd0101e9445ba882a01b24953006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c69f5d0409941ab9d41f33ab2ea5f0e",
            "placeholder": "​",
            "style": "IPY_MODEL_1834b3de7ae74b27992275bc76cb6af0",
            "value": "Map: 100%"
          }
        },
        "d797090887ba49c4add2b0b43ea38f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af36859ffc264ff69893e4b005a6d8c3",
            "max": 209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9e826da72384b05ae7de5d357311c16",
            "value": 209
          }
        },
        "04a3fec084e343b88328ef137a81862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918c826e337d45e698f16dd7d942bb4c",
            "placeholder": "​",
            "style": "IPY_MODEL_fb77710312a64f619f123a86bd1e599a",
            "value": " 209/209 [00:00&lt;00:00, 3484.20 examples/s]"
          }
        },
        "c8def0001b5444a0b45a1fd01f5e4bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c69f5d0409941ab9d41f33ab2ea5f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1834b3de7ae74b27992275bc76cb6af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af36859ffc264ff69893e4b005a6d8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e826da72384b05ae7de5d357311c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918c826e337d45e698f16dd7d942bb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb77710312a64f619f123a86bd1e599a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c3801c6e684b99a1563af49f7cc43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63b5defe17f34ac69f13a8cc274df900",
              "IPY_MODEL_21df4cbf56354a4485bd29cc0714204b",
              "IPY_MODEL_cc7e1f3d7b334eadb084e75a5832cc83"
            ],
            "layout": "IPY_MODEL_58ef502d013740e883b9762d220131cc"
          }
        },
        "63b5defe17f34ac69f13a8cc274df900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3834954b62b74711a002fdd36d4af4bc",
            "placeholder": "​",
            "style": "IPY_MODEL_bcc48745f85e45ad96f7cf5dbba0bcc2",
            "value": "Map: 100%"
          }
        },
        "21df4cbf56354a4485bd29cc0714204b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d58c1af0df4f9390164ba352f5ca28",
            "max": 209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_addbcaf2fe9f4fb09d95e1d4c695d96b",
            "value": 209
          }
        },
        "cc7e1f3d7b334eadb084e75a5832cc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc719852a4ee4b46a85f0f219d9de712",
            "placeholder": "​",
            "style": "IPY_MODEL_0d83779ed4344074aac5f20323fbad5f",
            "value": " 209/209 [00:00&lt;00:00, 1914.44 examples/s]"
          }
        },
        "58ef502d013740e883b9762d220131cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3834954b62b74711a002fdd36d4af4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc48745f85e45ad96f7cf5dbba0bcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5d58c1af0df4f9390164ba352f5ca28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "addbcaf2fe9f4fb09d95e1d4c695d96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc719852a4ee4b46a85f0f219d9de712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d83779ed4344074aac5f20323fbad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9a4c17da78349c29a0b72aaac331694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_933497998cc9430287521369de07d5a9",
              "IPY_MODEL_d13699d706e244e1b5cad4a463eea3b4",
              "IPY_MODEL_247b70e3c8ef453ca2b1cc4029150302"
            ],
            "layout": "IPY_MODEL_d199b8da76cc42c29c0978c171d8f858"
          }
        },
        "933497998cc9430287521369de07d5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c8b8a3da7d474dbd2fc263209965d2",
            "placeholder": "​",
            "style": "IPY_MODEL_52eedd207da546cab1779a26c9a6392a",
            "value": "Map: 100%"
          }
        },
        "d13699d706e244e1b5cad4a463eea3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0602c8209d494f0dacb4de7ce751f099",
            "max": 209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10cce9d020b14c7f8063cc5603f63db0",
            "value": 209
          }
        },
        "247b70e3c8ef453ca2b1cc4029150302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_602d6717c29c4dd3aea3894662ae2d6b",
            "placeholder": "​",
            "style": "IPY_MODEL_83fb4b60f1bd42978761dda7550b2f27",
            "value": " 209/209 [00:00&lt;00:00, 2041.83 examples/s]"
          }
        },
        "d199b8da76cc42c29c0978c171d8f858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c8b8a3da7d474dbd2fc263209965d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52eedd207da546cab1779a26c9a6392a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0602c8209d494f0dacb4de7ce751f099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10cce9d020b14c7f8063cc5603f63db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "602d6717c29c4dd3aea3894662ae2d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fb4b60f1bd42978761dda7550b2f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03e997ceb2e742a980fab26374e51ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a6a6203ff4e441596283b5a649f3566",
              "IPY_MODEL_b000c97cab6b43a084ba83c26819a11f",
              "IPY_MODEL_825f6238bb524eac80e980bbcc1e7c53"
            ],
            "layout": "IPY_MODEL_04085d9328404d7785a445ccbdf9bc40"
          }
        },
        "0a6a6203ff4e441596283b5a649f3566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0bc66d28e4d4818bd3c4c6ed78bec75",
            "placeholder": "​",
            "style": "IPY_MODEL_c110e58ec4a44535994b1a9ee55608b1",
            "value": "unsloth.Q4_K_M.gguf: 100%"
          }
        },
        "b000c97cab6b43a084ba83c26819a11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6edfa3ebfeb9409c90ab6c5acf82b467",
            "max": 2019377984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8685d791b6de44ef955d43b3920da1b7",
            "value": 2019377984
          }
        },
        "825f6238bb524eac80e980bbcc1e7c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ace759f2854b278018e9b0ad3cb2cb",
            "placeholder": "​",
            "style": "IPY_MODEL_3772a77e3b0e4c7bb0ed6a75f2a3da4d",
            "value": " 2.02G/2.02G [00:54&lt;00:00, 58.2MB/s]"
          }
        },
        "04085d9328404d7785a445ccbdf9bc40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bc66d28e4d4818bd3c4c6ed78bec75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c110e58ec4a44535994b1a9ee55608b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6edfa3ebfeb9409c90ab6c5acf82b467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8685d791b6de44ef955d43b3920da1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19ace759f2854b278018e9b0ad3cb2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3772a77e3b0e4c7bb0ed6a75f2a3da4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40ccbd8e3c7452189d559703b65bfc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0965bf189e5c453da15cc342ff567b5a",
              "IPY_MODEL_e3df2d556cc6442f841cf1e864c41a97",
              "IPY_MODEL_5d4ef03ade4c48008fbcba81f45af4f4"
            ],
            "layout": "IPY_MODEL_24d8a9ee003449ca92b2d0c362cfe69c"
          }
        },
        "0965bf189e5c453da15cc342ff567b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e12a5a12fe4ff3a42b29f9f19e44aa",
            "placeholder": "​",
            "style": "IPY_MODEL_be6ad0d1497f4d8b8d0463c672c6eef9",
            "value": "unsloth.Q8_0.gguf: 100%"
          }
        },
        "e3df2d556cc6442f841cf1e864c41a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e768bb48724ba59342c9e92ac76f68",
            "max": 3421899584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1580136dad2490fb79f4a406bc68e8a",
            "value": 3421899584
          }
        },
        "5d4ef03ade4c48008fbcba81f45af4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fff89b5d9fd444485b3288b3dd5ccff",
            "placeholder": "​",
            "style": "IPY_MODEL_67e2d7a3c19c4b77893d86b8657c216f",
            "value": " 3.42G/3.42G [01:19&lt;00:00, 37.0MB/s]"
          }
        },
        "24d8a9ee003449ca92b2d0c362cfe69c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e12a5a12fe4ff3a42b29f9f19e44aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6ad0d1497f4d8b8d0463c672c6eef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67e768bb48724ba59342c9e92ac76f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1580136dad2490fb79f4a406bc68e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fff89b5d9fd444485b3288b3dd5ccff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e2d7a3c19c4b77893d86b8657c216f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "789ae18eb363419eaa4f97dfed170531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_275578403bde4d40a32a15e8be81491c",
              "IPY_MODEL_c362a17171164a208d98f8f8d09d4843",
              "IPY_MODEL_f739984d782f4c5b93f7ee7b0de2546e"
            ],
            "layout": "IPY_MODEL_63d5b7750fa24822b8c2f7eb3fefe77f"
          }
        },
        "275578403bde4d40a32a15e8be81491c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034ff78731844d01b1de0b2bf501fe95",
            "placeholder": "​",
            "style": "IPY_MODEL_3d57abb2772b49388b6765e11113fee0",
            "value": "unsloth.Q5_K_M.gguf: 100%"
          }
        },
        "c362a17171164a208d98f8f8d09d4843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac698617c94a4f099ef834b8800b5977",
            "max": 2322154304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52906ccfb4ca4e6a8c7bccc089b7b43d",
            "value": 2322154304
          }
        },
        "f739984d782f4c5b93f7ee7b0de2546e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e267e5fcd6d456e81390f8a9b55730f",
            "placeholder": "​",
            "style": "IPY_MODEL_0219937e56d043ae9ecab745edd5b680",
            "value": " 2.32G/2.32G [00:59&lt;00:00, 51.5MB/s]"
          }
        },
        "63d5b7750fa24822b8c2f7eb3fefe77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034ff78731844d01b1de0b2bf501fe95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d57abb2772b49388b6765e11113fee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac698617c94a4f099ef834b8800b5977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52906ccfb4ca4e6a8c7bccc089b7b43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e267e5fcd6d456e81390f8a9b55730f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0219937e56d043ae9ecab745edd5b680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}